<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/">
    <title>HsienYu Cheng ｜ 鄭 先喻 </title>
    <link href="https://chenghsienyu.com/feed.xml" rel="self" />
    <link href="https://chenghsienyu.com" />
    <updated>2024-02-28T21:44:18+08:00</updated>
    <author>
        <name>HsienYu Cheng｜鄭先喻</name>
    </author>
    <id>https://chenghsienyu.com</id>

    <entry>
        <title>% consumption of computing</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/consumption-of-computing/"/>
        <id>https://chenghsienyu.com/consumption-of-computing/</id>
            <category term="2023"/>
            <category term="% consumption of computing"/>

        <updated>2024-01-17T05:07:20+08:00</updated>
            <summary>
                <![CDATA[
                    名稱：％ consumption of computing 媒材：VR headset, web application, machine learning server side application, game engine, display monitor. Link to website.
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p class="p1"><span class="s1">名稱：％</span> consumption of computing</p>
<p class="p1"><span class="s1">媒材：</span>VR headset, web application, machine learning server side application, game engine, display monitor.</p>
<p>Link to website.   <a href="https://detecting-percentage.vercel.app" target="_blank" rel="noopener noreferrer">Link for %</a></p>
<p>Offline version - Video:</p>
<figure class="post__video"><iframe loading="lazy" width="425" height="350" src="https://player.vimeo.com/video/903448051?title=0&amp;byline=0&amp;portrait=0&amp;color=8dc7dc&dnt=1" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
<p class="p3">簡述：</p>
<p class="p3">近代社會推進的進程，從個人電腦、網際網路到手持智慧型裝置與伺服器網路應用等等，作為一連串爆發式的前進，從社群網路到未來無密碼登入與許多正在萌芽的<span class="s2">web3</span>應用，也漸漸將人的生物識別特徵逐一連結，甚至生活習慣與行為，人也從擷取資訊到已經像是作為原料或是糧食一樣的角色存在於網路世界與網路應用中，這樣的現象也帶動了全線上框架的發展與衍伸出許多不同的商業應用，現代人也漸漸的習慣享受與遊戲於虛擬世界所建構的環境中。</p>
<p class="p3">作品為利用機器學習產出ＶＲ環景影像的自然場景，場景的產生基於使用者使用裝置瀏覽網路應用程式時，系統會記錄使用者裝置的電池狀態與容量百分比，去對應產生的ＶＲ場景風格，電池容量越低ＶＲ場景會趨近於天然與乾淨無破壞的景觀，反之如果電池容量百分比越高，場景則會趨近於人為破壞或是較為污染與負面的生態。作品同時也藉由紀錄伺服器端圖像與機器學習運算時所消耗的時間轉換為所消耗的電源功率，去產生圖表與視覺化資料，討論在大量依靠伺服器邊緣運算的當下，娛樂與資本的服務平台以及消費性的商品與市場所帶來的能源消耗與環境之間的平衡與破壞。</p>
<p class="p3">經由這種使用觀眾實體裝置的物理參數（電池容量與狀態）去影響與控制虛擬實境產出的自然場景去象徵技術的發展與環境之間的關係，也凸顯未來在伺服器運算技術如何與能源消耗和環境之間的平衡進行融合，這類應用的發展需要大量的資源，包括能源、原材料和水，作品也希望表現出這類資源的開採和使用對環境產生了不可忽視的影響，也反映出未來人在虛實世界上的邊界會產生更多新的交互作用與影響，那些影響也藉由政治、社會狀態、環境等等範疇上不斷的出現在我們所處的現實上。</p>
<p>Title: % Consumption of Computing</p>
<p>Medium: VR headset, web application, machine learning server side application, game engine, display monitor.</p>
<p>Brief Description:</p>
<p>In the progression of modern society, from personal computers, the internet to handheld smart devices and server network applications, etc., an explosive progression is evidenced. From social networking to future password-less login and many emerging Web3 applications, bio-identification features of people are gradually connected, as well as their habits and behavior. Humans have moved from information gatherers to being used as "material" or "food" in the digital world and internet applications. This phenomenon also boosts the development of an all-online framework and gives rise to many different commercial applications. Modern people are gradually getting used to the environment constructed in the virtual world through games.</p>
<p>This work uses machine learning to produce VR panoramic images of natural scenes. The generation of the scenes is based on the battery status and capacity percentage of the user's device when browsing the web application. The lower the battery capacity, the more the VR scene will tend to resemble a natural and undamaged view, while a higher battery percentage will yield scenes that lean towards human-caused damage or more polluted and negative ecosystems. By recording the server-side image and the time consumed by machine learning calculations, the work also generates charts and visualized data, discussing the balance and destruction between energy consumption and the environment brought about by entertainment, capital service platforms, consumer goods, and the market that heavily relies on edge computing at the server.</p>
<p>The work utilizes the physical parameters (battery capacity and status) of the audience's device to influence and control the generation of natural scenes in the VR, symbolizing the relationship between technological development and the environment, and highlighting how future server computing technology will be merged with energy consumption and environmental balance. The development of such applications requires a large amount of resources, including energy, raw materials, and water. The work hopes to express the indisputable impact that the extraction and use of such resources have on the environment. It reflects that in the future, the boundary between the virtual and real world is likely to generate more new interactions and influences, and these influences continually surface in our reality through politics, social state, and environment and other aspects.</p>
<figure class="post__video"><iframe loading="lazy" width="560" height="314" src="https://www.youtube-nocookie.com/embed/lhDOW3TfBUs" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
<p> </p>
<p> </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>There is Another Capital Beneath the Waves</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/there-is-another-capital-beneath-the-waves/"/>
        <id>https://chenghsienyu.com/there-is-another-capital-beneath-the-waves/</id>
        <media:content url="https://chenghsienyu.com/media/posts/50/de8793f9aa31f620be3a44b7f41fce2e.jpg" medium="image" />
            <category term="Project &amp; Work"/>
            <category term="2023"/>

        <updated>2023-09-30T23:40:46+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/50/de8793f9aa31f620be3a44b7f41fce2e.jpg" alt="" />
                    浪のしたにも都のさぶらふぞ Hsu Chai-Wei + Chang Ting-Tong + Cheng Hsien-Yu In collaboration with YCAM, 6 channel videos, VR performance Approx. 40&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/50/de8793f9aa31f620be3a44b7f41fce2e.jpg" class="type:primaryImage" alt="" /></p>
                <p>浪のしたにも都のさぶらふぞ</p>
<p>Hsu Chai-Wei + Chang Ting-Tong + Cheng Hsien-Yu In collaboration with YCAM, 6 channel videos, VR performance Approx. 40 min.許家維＋張碩尹＋鄭先喻 與YCAM合作，6頻道錄像、虛擬現實表演，約40分鐘,2023</p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/1ceda6d260fcc4b79c5887874f5a60e4.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/1ceda6d260fcc4b79c5887874f5a60e4-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/a316e9de357f1e83d4d3a8e20f880547.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/a316e9de357f1e83d4d3a8e20f880547-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/de8793f9aa31f620be3a44b7f41fce2e.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/de8793f9aa31f620be3a44b7f41fce2e-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/a2a1c7ade84eb66931a3d970fec768af.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/a2a1c7ade84eb66931a3d970fec768af-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/defe72291c94e0844cb123e35d61e160.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/defe72291c94e0844cb123e35d61e160-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/2cb6fbe0603c65b347971a260111f77a.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/2cb6fbe0603c65b347971a260111f77a-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/83b94a2c1f529dcdfafc5320d864be70.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/83b94a2c1f529dcdfafc5320d864be70-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/e0e55d9e0e89bc6b9528a1d320c62499.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/e0e55d9e0e89bc6b9528a1d320c62499-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/09e3b7bb9f4a34c4d8db4fd38daf72d7.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/09e3b7bb9f4a34c4d8db4fd38daf72d7-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/1312ec70d6a48ab05f3884ff7199cb01.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/1312ec70d6a48ab05f3884ff7199cb01-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/5f49511e5a60754ec1a36c1c3f85f8aa.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/5f49511e5a60754ec1a36c1c3f85f8aa-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/50/gallery/02a718fef786ab39da32f132281307c2.jpg" data-size="1920x1080"><img loading="lazy" src="https://chenghsienyu.com/media/posts/50/gallery/02a718fef786ab39da32f132281307c2-thumbnail.webp" alt="" width="720" height="405"></a></figure>
</div></div>
<p>《浪濤之下,亦有皇都》為山口媒體藝術中心(山口情報芸術センター,以下簡稱YCAM)與許家維、張碩尹、鄭先喻三位藝術家共創的新作。</p>
<p>三位藝術家各自囊括臺灣重要藝術獎項,並屢屢獲邀參與國際展演而受世界矚目。近年三人攜手於藝術計畫中著眼臺灣日治時期糖業發展,回顧臺灣與日本在歷史上的關係與現代化之軌跡。此作延續前述藝術計畫,以隨著日本現代化如火如荼發展工業、催生國際商港「門司港」的北九州市為背景,搬演製作日本傳統偶戲「人形淨琉璃」與當代動畫連動共構之劇,再加上展場中的舞台組成影像與現場演出交織的大作。</p>
<p>《浪濤之下,亦有皇都》作品舞台乃是二十世紀前葉隨日本現代化腳步如火如荼發展工業、催生國際商港「門司港」的北九州市門司區。今日門司區內的百年糖廠仍在營運中,且過去與虎尾糖廠曾屬同一個企業傘下,可見虎尾與門司兩鎮在歷史上的緊密連結。兩鎮另一共同點則是在二戰期間皆被視為戰略要塞,並在戰爭白熱化之際遭受大規模空襲。本作疊合門司與門司港的現代化、第二次世界大戰的歷史及在地流傳的平家異聞等跨時空又游離於事實與 傳說之際的題材,並使日本傳統偶戲「人形淨琉璃」、當代動畫技術、音樂與展覽現場演出等古今表演藝術交織共構。新作標題「浪濤之下,亦有皇都」,更是引用了《平家物語》中描述壇之浦戰爭的段落。</p>
<p>本作中「操偶師與人偶」、「表演者與數位分身」象徵著「操縱與被操縱的關係」。而驅動這般不斷歷史重演又彼此拉鋸擺盪關係的驅動力又究竟為何?本作使傳統與當代藝術表現形式相織應和,在現實世界和虛擬世界往來穿梭的同時向觀者探問。</p>
<p>撮影：山中慎太郎（Qsyum!）</p>
<p>写真提供：山口情報芸術センター［YCAM］</p>
<p>There is Another Capital Beneath the Waves is a collaborative work between The Yamaguchi Center for Arts and Media [YCAM] and artists Chia-Wei Hsu, Ting-Tong Chang, and Hsien-Yu Cheng.</p>
<p>Individually, each of the artists is an internationally operating and reputed artist who has won major art awards in Taiwan in the past, and has participated in art exhibitions around the world. In recent years, the three of them have been collaborating on a project exploring the memory of modernization and historical relations between Taiwan and Japan, inspired by aspects of industrial sugar production in Taiwan during the time of Japanese rule.</p>
<p>There is Another Capital Beneath the Waves is a work that was realized as part two of Crystal Seeding(2021). It is set in Moji, a town in Kitakyushu where a sugar mill is still operating today. The exhibition looks from various angles at the memory of the two towns, which seem to be mirroring each otherʼs fate within the history of modernization in East Asia.</p>
<p>There is a sugar mill also in Moji today, which used to be operated by the same company that also operated a mill in Huwei, Taiwan. This is how the two towns have been connected through sugar. Both were strategically important bases during the war, and they both suffered severe damage in air raids when the war intensified.</p>
<p>In this work, the memories of war and modernization in Moji and Moji Port are portrayed by means of Japanese traditional joruri puppet theater, CG animation, music and live performance, while also overlapping with the famous local tale of the Heike clan. The title is in fact a line from the Heike Monogatari that describes scenes of the Battle of Dannoura.</p>
<p>The movements of the puppet masters and puppets, performers and avatars, symbolically suggest the complexly tangled relationship of “controlling and being controlled.” What exactly is the driving force that has repeatedly generated this relationship throughout history? This is the question that this work inspires the viewer to explore through a mixture of traditional and contemporary styles, while moving back and forth between the real and the virtual world.</p>
<p>Photo by Shintaro Yamanaka (Qsyum!)</p>
<p>Courtesy of Yamaguchi Center for Arts and Media [YCAM]</p>
<figure class="post__video"><iframe loading="lazy" width="695" height="572" style="width: 695px; height: 572px;" src="https://player.vimeo.com/video/841453930?title=0&amp;byline=0&amp;portrait=0&amp;color=8dc7dc&dnt=1" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
<p>Cast: Bunraku Puppeteer: YOSHIDA Tamasuke, KIRITAKE Monyoshi, YOSHIDA Tamamichi (BUNRAKU-KYOKAI) | Tayu: TAKEMOTO Tomowaka | Shamisen Player: TANAKA Yumiko | Percussionist: Taikimen (YAMAZAKI Taiki) | Lab Researcher: ITO Takayuki* | VR Performer: SAKAI Haruka, CHEN Ciou-Ye</p>
<p>Artististic Direction: HSU Chia-Wei, CHANG Ting-Tong, CHENG Hsien-Yu | Curation: YOSHIZAKI Kazuhiko* | Technical Direction: TOKISATO Mitsuru*, OWAKI Richi*, ITO Takayuki* | Project Management: CHAO I-Tian | Research &amp; Shooting Coordination: IWAMOTO Fumiwo, IKEGAMI Takahiro (Mojiko Art Platform), CHAO I-Tian</p>
<p>Sound Direction: HUI Tak-Cheung | &gt;Composition of Joruri and Taisho-koto: TANAKA Yumiko | Composition of Shamisen: TANAKA Yumiko, HUI Tak-Cheung | Sound Design: HUI Tak-Cheung | Sound Mix: HUI Tak-Cheung | Sound Support: TANAKA Yumiko</p>
<p>Video Direction: HSU Chia-Wei | Shooting Direction: MORIUCHI Yasuhiro | Shooting Crew: MORIUCHI Yasuhiro, CHENG Yu-Chen, TOKISATO Mitsuru*, YAMAOKA Daichi*, OWAKI Richi* | Drone Shooting: SHIRASAWA Tetsuhiro | Motion Capture: OWAKI Richi*, TOKISATO Mitsuru* | 3D Scan: TAKAHARA Fumie*, TOKISATO Mitsuru* | Sound Recording: KASAI Toshihiko, KASE Takuma, NAKAUE Junji*, ITO Takayuki* | Lighting: TAKAHARA Fumie* | Costume Design: CHEN Hikky | Make-up: CHENG Hsien-Yu, CHEN Hikky | Production Stage Management: NG Clarence* | Instrument Design: CHANG Ting-Tong | Instrument Production: LIN Kuo-Wei, OWAKI Richi*, TOKISATO Mitsuru* | Alcohol Production: ITO Takayuki*, TAKAHARA Fumie*, OHTA Hazuki* | Set Design: CHANG Ting-Tong | Set Production: SUPER FACTORY, OWAKI Richi*, ANDO Mitsuhito*, ISHIZAKI Tomoko*, SHOBUN Ayumi* | Video Editing: HSU Chia-Wei | Video Coloring: YANG Tzu-Yi | VFX: TSAI Quint　YANG Tzu-Yi | CG Production: HANZAWA Tomoro | CG Animation: TOKISATO Mitsuru* | CG Animation Assistance: ITAKURA Hayato* | Performance Direction: CHANG Ting-Tong | Stage Management: NG Clarence* | Installation Design: CHANG Ting-Tong, CHENG Hsien-Yu | Media Sync System: NAKAUE Junji* | Coordination: MENON Kartika*, FUKUCHI Hikari*, NAKAJIMA Chisako</p>
<p>Script: YANG Kai-Ting, CHANG Ting-Tong | Japanese Translation: IKEDA Lily Ai | English Translation: IWAMOTO Fumiwo, IKEGAMI Takahiro | Japanese Translation Support: YAMAMOTO Hiroki + h (Inu no senaka-za), TANAKA Yumiko | Subtitles: Cheng Yu Chen, Hayato Itakura*</p>
<p>Special Thanks: Mojiko Art Platform, Kanmon Seito Co. Ltd., Shin-Moji Saiseki Co. Ltd., Sankiro, Kitakyushu Film Commission, Taiwan Sugar Coporation Huwei Sugar Factory, people in Moji and Mojiko who cooperatated all those who cooperated in the shooting at Moji and Mojiko</p>
<p>This project has been granted subsidy of National Culture and Arts Foundation.</p>
<p>演員: 文樂傀儡操演者：吉田玉助、桐竹紋吉、吉田玉路（公益財團法人文樂協會）| 太夫：竹本友和嘉 | 三味線及大正琴演奏者：田中悠美子 | 打擊樂手：Taikimen（山﨑大輝）| 實驗室研究員：伊藤隆之*| 虛擬現實表演者：坂井遥香、陳秋燁 ※雙人演出</p>
<p>藝術指導：許家維、張碩尹、鄭先喻 | 策展：吉﨑和彥* | 技術指導：時里充*、大脇理智*、伊藤隆之* | 專案管理：趙宜恬 | 研究拍攝協調：岩本史緒、池上貴弘（門司港藝術平台）、趙宜恬</p>
<p>音樂指導：許德彰 | 浄瑠璃及大正琴作曲：田中悠美子 | 三味線作曲：田中悠美子、許德彰 | 打擊樂作曲：許德彰 | 音響設計：許德彰 | 音樂混音：許德彰 | 音樂協助：田中悠美子</p>
<p>影像導演：許家維 | 攝影導演：森内康博 | 攝影：森内康博、鄭禹晨、時里充*、山岡大地*、大脇理智* | 無人機攝影：白澤哲浩 | 動作捕捉：大脇理智*、時里充*</p>
<p>3D掃描：高原文江*、時里充* | 錄音：葛西俊彥、加瀬拓真、中上淳二*、伊藤隆之* | 照明：高原文江* | 服裝設計：陳必綺 | 化妝：鄭先喻、陳必綺 | 製作管理：クラレンス・ン* | 樂器設計：張碩尹 | 樂器製作：林國瑋、張碩尹、鄭先喻、大脇理智* | 酒類製造：伊藤隆之*、高原文江*、太田遥月* | 佈景設計：張碩尹 | 美術：超級工廠、大脇理智*、石崎智子*、正分あゆみ*、時里充* | 影像剪輯：許家維 | 色彩校正：楊子逸 | 視覺特效：蔡承錕、 楊子逸 | CG製作：半澤智朗 | CG動畫：時里充* | CG動畫助理：板倉勇人* | 表演指導：張碩尹 | 舞台監督：クラレンス・ン* | 影子戲佈置：安藤充人* | 裝置藝術設計：張碩尹、鄭先喻 | 媒體同步系統構建：中上淳二* | 協調：卡爾蒂卡・梅農*、福地ひかり*、仲島智紗子</p>
<p> </p>
<p>劇本：楊凱婷、張碩尹 | 日本語字幕翻譯：池田リリィ茜藍 | 英語字幕翻譯：岩本史緒 | 浄瑠璃日本語翻譯修整：田中悠美子 | 劇本日本語翻譯協助：山本浩貴＋ｈ（いぬのせなか座）、田中悠美子 | 字幕製作：鄭禹晨、板倉勇人*</p>
<p>特別感謝：門司港藝術平台、關門製糖股份有限公司、新門司砕石工業股份有限公司、三宜樓、北九州電影委員會、虎尾糖廠、門司・門司港提供的拍攝協助</p>
<p>本作品得到台灣國家文化藝術基金會的資助。</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>A slightly different browser</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/a-slightly-different-browser/"/>
        <id>https://chenghsienyu.com/a-slightly-different-browser/</id>
        <media:content url="https://chenghsienyu.com/media/posts/49/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02.jpeg" medium="image" />
            <category term="[.user          ]"/>
            <category term="Project &amp; Work"/>
            <category term="2023"/>

        <updated>2024-02-27T18:06:03+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/49/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02.jpeg" alt="" />
                    2023 customized web browser, on-site real-time audio-visual installation “A slightly different browser”透過模擬量子網路的加密方式，將網路使用者的動作（如滑鼠移動、滾動和點擊以及瀏覽器DOM的內容轉為光影）再透過模擬的量子加密的方式傳輸到展覽現場，將在另一空間中即刻轉換為視覺所見的物理光，以感官所見的物理光回歸至人類的直觀感受。操作瀏覽器時獲得的資訊即時性同時連動了直觀的視覺經驗。也同時運用量子科學和日常技術之間的交會去創造並且實驗新的感知和溝通表達方式。量子網路模擬強調了參與者行動的隱蔽性，而視覺效果的逃脫性則挑戰觀察者將視覺轉化為語言的能力。結果是一次對所見與不見之間的複雜關係、參與者和旁觀者之間的互動以及將量子概念與感知領域相結合的深入探索。 "A slightly different browser" uses a simulated quantum&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/49/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02.jpeg" class="type:primaryImage" alt="" /></p>
                <p class="p1">2023</p>
<p>customized web browser, on-site real-time audio-visual installation</p>
<p class="p1"><span class="s1">“A slightly different browser”</span>透過模擬量子網路的加密方式，將網路使用者的動作（如滑鼠移動、滾動和點擊以及瀏覽器<span class="s1">DOM</span>的內容轉為光影）再透過模擬的量子加密的方式傳輸到展覽現場，將在另一空間中即刻轉換為視覺所見的物理光，以感官所見的物理光回歸至人類的直觀感受。操作瀏覽器時獲得的資訊即時性同時連動了直觀的視覺經驗。也同時運用量子科學和日常技術之間的交會去創造並且實驗新的感知和溝通表達方式。量子網路模擬強調了參與者行動的隱蔽性，而視覺效果的逃脫性則挑戰觀察者將視覺轉化為語言的能力。結果是一次對所見與不見之間的複雜關係、參與者和旁觀者之間的互動以及將量子概念與感知領域相結合的深入探索。</p>
<p class="p3">"A slightly different browser" uses a simulated quantum network encryption method to transmit the actions of internet users (such as mouse movements, scrolling, clicking, and browser DOM content) as light and shadows to the exhibition site. This transmission is achieved through simulated quantum encryption, which is then instantly transformed into physical light visible in physical space, bringing sensory perception back to human intuition. The real-time nature of browsing also synchronizes with the intuitive visual experience. Additionally, the work explores the intersection of quantum science and everyday technology to create and experiment with new forms of perception and communication. The simulation of the quantum network emphasizes the secrecy of the participants' actions, while the concealment of visual effects challenges the observer's ability to translate visual experiences into language. The result is a deep exploration of the complex relationship between the seen and the unseen, the interaction between participants and observers, and the integration of quantum concepts into the field of perception.</p>
<p>web browser download link:</p>
<p><a href="https://github.com/HsienYu/QMin/releases/tag/1.0.0" target="_blank" rel="noopener noreferrer">https://github.com/HsienYu/QMin/releases/tag/1.0.0</a></p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="2">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/49/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02.jpeg" data-size="3000x2171"><img loading="lazy" src="https://chenghsienyu.com/media/posts/49/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02-thumbnail.webp" alt="" width="720" height="521"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/49/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_01.jpeg" data-size="3000x2072"><img loading="lazy" src="https://chenghsienyu.com/media/posts/49/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_01-thumbnail.webp" alt="" width="720" height="497"></a></figure>
</div></div>
<p class="p1">seeing. Concealment and revelation, participation and observation, visual engagement and linguistic expression interact, challenging established notions of interaction, recording, and perception.</p>
<figure class="post__video"><iframe loading="lazy" width="695" height="572" style="width: 695px; height: 572px;" src="https://player.vimeo.com/video/865813598?title=0&amp;amp;byline=0&dnt=1" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
<div class="content">
<div class="description" data-fieldname="content">
<p>Photo by Eslite gallery</p>
</div>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Around 7 Meters is more fun</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/around-7-meters-is-more-fun/"/>
        <id>https://chenghsienyu.com/around-7-meters-is-more-fun/</id>
        <media:content url="https://chenghsienyu.com/media/posts/48/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" medium="image" />
            <category term="[.user          ]"/>
            <category term="Project &amp; Work"/>
            <category term="2023"/>

        <updated>2024-02-28T21:44:18+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/48/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" alt="" />
                    2023 joystick, display, customized software, camera and metal, machine learning algorithms Dimension variable (minimum size: 7 meter ) “Around 7&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/48/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" class="type:primaryImage" alt="" /></p>
                <p class="p1">2023</p>
<p>joystick, display, customized software, camera and metal, machine learning algorithms</p>
<p>Dimension variable (minimum size: 7 meter )</p>
<p class="p2"><span class="s1">“Around 7 meters is more fun”</span>創造一個特殊的情境，藉由情境與限制，去轉變溝通方式。參與者為了理解展示的視覺效果，不僅需要仰賴觀察者的描述、描繪和表達，更需要這些來傳達意義。這種互動促進了參與者和觀察者之間更緊密的合作，彌合了所見和所未見之間的差距，重新定義了人類感知的多面性。其中也運用機器學習的方式，去限制操作參與者無法看見其自己創造的結果，而觀察者也無法運用相機紀錄其結果，這兩種規則去賦予軟體表現接近於人類的情感邏輯，藉由此方法，去製造特殊的感知與互動經驗，重新思考可見和不可見之間的關係。</p>
<p class="p1">"Around 7 meters is more fun" creates a unique context that transforms communication by exploiting contextual elements and visuality constraints. In order to<span class="Apple-converted-space">  </span>understand the visual effects generated, participants rely not only on the observer's descriptions, depictions, and expressions but also need these to convey some meaning. This interaction triggers a closer collaboration between participants and observers, bridging the gap between the seen and the unseen and redefining the multiplicity of human perception. Machine learning<span class="s1">（</span>ReID and GroundingDino combine with prompts to objects and motion recognition.<span class="s1">）</span> is used to restrict participants from seeing the output of their own interventions, while observers are deprived from using their cameras to record these results. These two rules provide the software with a closer approximation to human emotional and social logic, creating a unique experience of perception and interaction from which to rethink the relationship between the visible and the invisible.</p>
<p class="p2"> </p>
<p class="p1">***The operator will never see the image they create.</p>
<p class="p2"> </p>
<p class="p1">In an environment saturated with internet information, continuing from traditional mass media to today's short visual and audio experiences, the way humans receive sensory stimuli has changed significantly on the informational level. Communication and understanding messages are markedly different from the past. In the exhibition, observers or audiences become witnesses, translating visual experiences into language and other non-visual forms of communication. This process activates a special relationship bet.</p>
<p class="p2"> </p>
<p class="p1">Technical Details:</p>
<p class="p1">This work involves two distinct machine learning models and algorithms. ReID (Person Re-Identification) aims to assist installations in remembering who is operating the joystick. Therefore, when the operator approaches the installation screen, the system will erase the image. Thanks to person re-identification, even after the operator has left, the system will still be able to recognize the individual for a certain period of time.</p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/48/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" data-size="3000x2000"><img loading="lazy" src="https://chenghsienyu.com/media/posts/48/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023-thumbnail.webp" alt="" width="720" height="480"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/48/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_03.jpeg" data-size="3000x1956"><img loading="lazy" src="https://chenghsienyu.com/media/posts/48/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_03-thumbnail.webp" alt="" width="720" height="469"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/48/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_02.jpeg" data-size="3000x2090"><img loading="lazy" src="https://chenghsienyu.com/media/posts/48/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_02-thumbnail.webp" alt="" width="720" height="502"></a></figure>
</div></div>
<figure class="post__video">
<figure class="post__video"><iframe loading="lazy" width="425" height="350" src="https://player.vimeo.com/video/865813598?title=0&amp;amp;byline=0&dnt=1" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
<span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Photo by Eslite gallery</span></figure>
            ]]>
        </content>
    </entry>
    <entry>
        <title>[.user            ]</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/user/"/>
        <id>https://chenghsienyu.com/user/</id>
        <media:content url="https://chenghsienyu.com/media/posts/47/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" medium="image" />
            <category term="Solo Exhibition"/>

        <updated>2024-02-14T16:05:33+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/47/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" alt="" />
                    "Embracing the Enigma Between Visibility and Expression” The exhibition [.user ] explores the complexity of human perception and the interaction&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/47/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023.jpg" class="type:primaryImage" alt="" /></p>
                <p class="p1">"Embracing the Enigma Between Visibility and Expression”</p>
<p class="p1">The exhibition [<span class="s1">.user</span><span class="Apple-converted-space">            </span>] explores the complexity of human perception and the interaction between participants and observers in the exhibition space through the interplay of participant actions, observer perspectives, and the elusiveness of visual effects. By creating an environment where visibility is elusive and understanding relies on verbal communication, the works provide evidence of the intricate interdependence between human sensory perception, interpersonal connections, and the essence of seeing. Concealment and revelation, participation and observation, visual engagement and linguistic expression interact, challenging established notions of interaction, recording, and perception.</p>
<p class="p1">"A slightly different browser" uses a simulated quantum network encryption method to transmit the actions of internet users (such as mouse movements, scrolling, clicking, and browser DOM content) as light and shadows to the exhibition site. This transmission is achieved through simulated quantum encryption, which is then instantly transformed into physical light visible in physical space, bringing sensory perception back to human intuition. The real-time nature of browsing also synchronizes with the intuitive visual experience. Additionally, the work explores the intersection of quantum science and everyday technology to create and experiment with new forms of perception and communication. The simulation of the quantum network emphasizes the secrecy of the participants' actions, while the concealment of visual effects challenges the observer's ability to translate visual experiences into language. The result is a deep exploration of the complex relationship between the seen and the unseen, the interaction between participants and observers, and the integration of quantum concepts into the field of perception.</p>
<p>web browser download link:</p>
<p><a href="https://github.com/HsienYu/QMin/releases/tag/1.0.0" target="_blank" rel="noopener noreferrer">https://github.com/HsienYu/QMin/releases/tag/1.0.0</a></p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="2">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02-2.jpeg" data-size="3000x2171"><img loading="lazy" src="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_02-2-thumbnail.webp" alt="" width="720" height="521"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_01-3.jpeg" data-size="3000x2072"><img loading="lazy" src="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-a-slightly-different-browser-2023_01-3-thumbnail.webp" alt="" width="720" height="497"></a></figure>
</div></div>
<p class="p1">"Around 7 meters is more fun" creates a unique context that transforms communication by exploiting contextual elements and visuality constraints. In order to<span class="Apple-converted-space">  </span>understand the visual effects generated, participants rely not only on the observer's descriptions, depictions, and expressions but also need these to convey some meaning. This interaction triggers a closer collaboration between participants and observers, bridging the gap between the seen and the unseen and redefining the multiplicity of human perception. Machine learning is used to restrict participants from seeing the output of their own interventions, while observers are deprived from using their cameras to record these results. These two rules provide the software with a closer approximation to human emotional and social logic, creating a unique experience of perception and interaction from which to rethink the relationship between the visible and the invisible.</p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="1">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023-2.jpg" data-size="3000x2000"><img loading="lazy" src="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023-2-thumbnail.webp" alt="" width="720" height="480"></a></figure>
</div></div>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="2">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_02.jpeg" data-size="3000x2090"><img loading="lazy" src="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_02-thumbnail.webp" alt="" width="720" height="502"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_03.jpeg" data-size="3000x1956"><img loading="lazy" src="https://chenghsienyu.com/media/posts/47/gallery/eslitegalleryviewingroom-hsienyu-cheng-around-7-meters-is-more-fun-2023_03-thumbnail.webp" alt="" width="720" height="469"></a></figure>
</div></div>
<p class="p3">Both pieces also convey complex dynamics between observers and perception itself. The exhibition [.user<span class="Apple-converted-space">            </span>], by engaging the audience in a responsive environment, attempts to address the fragmentation of identity and the workings of personal relationships into atomized individual expressions that resonate in today's environment of information networks, social media, and gaming culture. The way of receiving and releasing sensory stimuli has undergone significant changes at the information level and, similarly, external behaviors have changed. Communication and information are indeed different from the past. In the exhibition, observers or audiences become witnesses, translating visual experiences into language and other non-visual forms of communication. This process activates a special relationship between participants and observers, bridging the gap between the seen and the unseen. Furthermore, by transforming encrypted data into visible light, visual representations of encrypted actions are generated in simultaneous spaces. By triggering the sensory perception of users, this exhibition reflects on the possible connections of their actions in the virtual and physical realms.</p>
<figure class="post__video"><iframe loading="lazy" width="695" height="572" style="width: 695px; height: 572px;" src="https://player.vimeo.com/video/865813598?title=0&amp;amp;byline=0&dnt=1" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></figure>
<p><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Photo by Eslite gallery</span><br><br><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">展期：2023年9月16日—10月14日</span><br><br><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">地點：誠品畫廊丨台灣110055台北市信義區菸廠路88號B1（誠品生活松菸店）</span><br><br><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">開放時間：週二～週六 11:00-19:00（日、一公休）</span><br><br><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">多媒體設備贊助：洪建全基金會、台灣松下電器</span></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Collector - 收集者</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/collector-shou-ji-zhe/"/>
        <id>https://chenghsienyu.com/collector-shou-ji-zhe/</id>
        <media:content url="https://chenghsienyu.com/media/posts/46/Xiang-Ya-Qia_Zheng-Xian-YuZheng_10x15cm.jpg" medium="image" />
            <category term="Solo Exhibition"/>

        <updated>2023-05-03T23:01:23+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/46/Xiang-Ya-Qia_Zheng-Xian-YuZheng_10x15cm.jpg" alt="" />
                    Afterlife Portrait 2011 Portrait 2013 -Douglas Engelbart 「我常常會捨不得買新的東西，與其購買，亦常常會有自己動手做一個出來看看的想法與行動。久而久之，我養成了使用回收電器，或是改裝廢棄物件、零件以再利用的習慣。」--- 鄭先喻 在這次「收集者版本1.0.0」中，藝術家鄭先喻將展出五件全新創作，這些作品都將再次利用他所收集來的物件，重新建構、轉化自己對於生活中不平的世間事物。「收集者」這個計畫。它不只收集了被人們視為無用的材料，也收集著這世間中假的生命道德、虛假的和平以及人性的逞強。 “To reuse wasted products or buying new things, I sometimes&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/46/Xiang-Ya-Qia_Zheng-Xian-YuZheng_10x15cm.jpg" class="type:primaryImage" alt="" /></p>
                <p><a href="https://chenghsienyu.com/afterlife/" target="_blank" rel="noopener noreferrer">Afterlife</a></p>
<p><a href="https://chenghsienyu.com/portrait-2011/" target="_blank" rel="noopener noreferrer">Portrait 2011</a></p>
<p><a href="https://chenghsienyu.com/portrait-2013-douglas-engelbart/">Portrait 2013 -Douglas Engelbart</a></p>
<p><span style="font-weight: 400;">「我常常會捨不得買新的東西，與其購買，亦常常會有自己動手做一個出來看看的想法與行動。久而久之，我養成了使用回收電器，或是改裝廢棄物件、零件以再利用的習慣。」</span><span style="font-weight: 400;">--- </span><span style="font-weight: 400;">鄭先喻</span></p>
<p style="font-weight: 400;"> </p>
<p style="font-weight: 400;">在這次「收集者版本1.0.0」中，藝術家鄭先喻將展出五件全新創作，這些作品都將再次利用他所收集來的物件，重新建構、轉化自己對於生活中不平的世間事物。「收集者」這個計畫。它不只收集了被人們視為無用的材料，也收集著這世間中假的生命道德、虛假的和平以及人性的逞強。<br><br><br></p>
<p>“To reuse wasted products or buying new things, I sometimes struggle with them. Then I  use to make one by myself instead of buying. Over a long period of time, I have this habit and develop some skills via those process by modifying, recycling some E-waste or secondhand materials.” ---Hsien-Yu CHENG</p>
<p> </p>
<p>This process is also concerned with his creative works. he tries to symbolize or bring some thoughts and things are happened around our life, society even nature that he doesn't like into his works. Maybe those things that he doesn't want to see or he doesn't like are not really important for many people, but he still keep collecting those phenomenons that are happened around us. So he starts to have this project “Collector”. It’s not only collecting abandoned objects or E-waste, it’s also collecting sanctimonious justice, value and humanity.</p>
<p> </p>
<p>Hsien-Yu CHENG presents 5 works In [collector 1.0.0] at tamtamART TAIPEI. IPIX this time. Three of them are related to his thoughts about perspective between human and life. The other two, one is that he would like to express respect to the inventor of computer mice. The other one is a kind of experimental prototype, it’s about how to generate energy by bio materials and eco-tech.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Eyes、Ears、Nose, Tongues...those parts</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/eyesearsnose-tonguesthose-parts/"/>
        <id>https://chenghsienyu.com/eyesearsnose-tonguesthose-parts/</id>
        <media:content url="https://chenghsienyu.com/media/posts/45/70039162638__607D8166-384D-4816-89CB-E04C21CDD058.jpg" medium="image" />
            <category term="Solo Exhibition"/>

        <updated>2023-04-10T19:48:58+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/45/70039162638__607D8166-384D-4816-89CB-E04C21CDD058.jpg" alt="" />
                    Eyes、Ears、Nose, Tongues...those parts @ the NCCU Art &amp; Culture Center 《Eyes、Ears、Nose, Tongues...those parts》作為臉部的感官部件，展覽從顏面為人類接受訊息以及最接近大腦的人體部位作為出發，討論人類物種有著不同的臉部相貌，並延伸由視覺去辨識臉部作為個人與主體的象徵與代表，甚至為身份確認的方法。 在近代電腦視覺的演進，Facial recognition（臉部辨識）系統從基於類間變化及類內變化的方式，藉由機器學習轉為接近強人工智慧（Strong AI）的方向。同時，隱私權也因為網路與監視科技的發展變得越來越為重要。未來科技發展亦會逐漸朝向Passwordless（無密碼登入）方向演進，所以生理訊息類的加密方式與辨識將會成為研發重點。例如：臉部解鎖，這類的應用為目前個人行動裝置身份確認的方法之一。 臉，我們藉由眼睛觀看對方，直接、間接透過螢幕或其他方式認知個體。作品《這可能是你》以網路即時留言者暱稱作為搜尋臉部圖像的關鍵，藉由合成資料與機器學習，產出許多不同的亞洲臉孔以及假個資，創造出「這有可能是你」的情境假象，用以質問與顯現個人的數位足跡與龐大網路資料能夠作為軟體系統對於人類的想像。這種方式並非像透過光的折射，再藉由大腦的化學生理變化去理解畫面，而是藉由每一個Pixel dot（像素點），再經過演算方式的一連串處理，當電腦軟體將人形辨識為物件時，知道依據型態去定義人，再加上物件是否移動的邏輯，它能更確認這是個會動的人，而不是一個靜態的人型看板。軟體藉由參考行為與環境的參數及變化，增強對於物件或事件的定義。 作品《肖像2011》運用回收材料製作機械人頭，賦予機械單一種人類的情感表現方式。當展覽現場沒有人時，裝置會開始哭泣流淚。人在情感波動下，哭泣的行為表現方式，許多人會將之隱藏。這是一種安靜隱密的情緒，隱藏的行為可能較難在冷冰冰的機械上表現，但在現今網路電商的消費者行為分析，追蹤喜好的廣告投放，或許能找到相似的表現。某類商品雖然較優惠，但因為消費者不常瀏覽這類的商品，所以就不寄送電子報或是推播通知。這類追蹤消費者使用習慣的方式，由網站記錄何時瀏覽，據以判斷於何時投放促銷方案，才能促進買氣。 上述建構在基礎網路架構的資料搜集，其中以CCTV閉路與網路攝影系統最為常見，但囿於各地法律，而具不同的規範。作品《證件照拍攝指南》為2021年與陳珊妮、談宗藩合作的共同行動。該行動起源於陳珊妮遺失身分證，我們運用IoT（物聯網）搜尋引擎「Shodan」找尋在臺北市區安全性較低的網路攝影機，透過攝影機畫面判斷攝影機地點，然後到現場拍攝身份證件照。照片沖洗完成後，再到戶政事務所補辦身份證。簡單的駭客行為作為圖像的產出，將其圖像放置在國家身份證件上，是開始這個行動的出發點之一。《證件照拍攝指南On-Site》為2023年政大駐校計畫再創作版本，將延伸2021年的版本而為實體裝置作品。&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/45/70039162638__607D8166-384D-4816-89CB-E04C21CDD058.jpg" class="type:primaryImage" alt="" /></p>
                <p><a href="http://artist.nccu.edu.tw/exhibition.html" target="_blank" rel="noopener noreferrer">Eyes、Ears、Nose, Tongues...those parts</a></p>
<p>@ the NCCU Art &amp; Culture Center</p>
<p><i>《Eyes、Ears、Nose, Tongues...those parts》</i>作為臉部的感官部件，展覽從顏面為人類接受訊息以及最接近大腦的人體部位作為出發，討論人類物種有著不同的臉部相貌，並延伸由視覺去辨識臉部作為個人與主體的象徵與代表，甚至為身份確認的方法。</p>
<p>在近代電腦視覺的演進，Facial recognition（臉部辨識）系統從基於類間變化及類內變化的方式，藉由機器學習轉為接近強人工智慧（Strong AI）的方向。同時，隱私權也因為網路與監視科技的發展變得越來越為重要。未來科技發展亦會逐漸朝向Passwordless（無密碼登入）方向演進，所以生理訊息類的加密方式與辨識將會成為研發重點。例如：臉部解鎖，這類的應用為目前個人行動裝置身份確認的方法之一。</p>
<p>臉，我們藉由眼睛觀看對方，直接、間接透過螢幕或其他方式認知個體。作品《這可能是你》以網路即時留言者暱稱作為搜尋臉部圖像的關鍵，藉由合成資料與機器學習，產出許多不同的亞洲臉孔以及假個資，創造出「這有可能是你」的情境假象，用以質問與顯現個人的數位足跡與龐大網路資料能夠作為軟體系統對於人類的想像。這種方式並非像透過光的折射，再藉由大腦的化學生理變化去理解畫面，而是藉由每一個Pixel dot（像素點），再經過演算方式的一連串處理，當電腦軟體將人形辨識為物件時，知道依據型態去定義人，再加上物件是否移動的邏輯，它能更確認這是個會動的人，而不是一個靜態的人型看板。軟體藉由參考行為與環境的參數及變化，增強對於物件或事件的定義。</p>
<p>作品《肖像2011》運用回收材料製作機械人頭，賦予機械單一種人類的情感表現方式。當展覽現場沒有人時，裝置會開始哭泣流淚。人在情感波動下，哭泣的行為表現方式，許多人會將之隱藏。這是一種安靜隱密的情緒，隱藏的行為可能較難在冷冰冰的機械上表現，但在現今網路電商的消費者行為分析，追蹤喜好的廣告投放，或許能找到相似的表現。某類商品雖然較優惠，但因為消費者不常瀏覽這類的商品，所以就不寄送電子報或是推播通知。這類追蹤消費者使用習慣的方式，由網站記錄何時瀏覽，據以判斷於何時投放促銷方案，才能促進買氣。</p>
<p>上述建構在基礎網路架構的資料搜集，其中以CCTV閉路與網路攝影系統最為常見，但囿於各地法律，而具不同的規範。作品《證件照拍攝指南》為2021年與陳珊妮、談宗藩合作的共同行動。該行動起源於陳珊妮遺失身分證，我們運用IoT（物聯網）搜尋引擎「Shodan」找尋在臺北市區安全性較低的網路攝影機，透過攝影機畫面判斷攝影機地點，然後到現場拍攝身份證件照。照片沖洗完成後，再到戶政事務所補辦身份證。簡單的駭客行為作為圖像的產出，將其圖像放置在國家身份證件上，是開始這個行動的出發點之一。《證件照拍攝指南On-Site》為2023年政大駐校計畫再創作版本，將延伸2021年的版本而為實體裝置作品。</p>
<p class="tx_en">The exhibition <i>《Eyes, Ears, Nose, Tongues...those parts》 Those Parts</i> revolves around the face in order to discuss issues of identity related to contemporary uses of technology, as online consumer behaviour and privacy, facial recognition and surveillance systems. The face is arguably the part of the human body that is most receptive to receiving messages. It is also the closest part to the brain. In machine learning systems and network infrastructures based on data recollection, the visual recognition of faces serves as a symbolic representation of individual subjects and as a method of identity verification.</p>
<p class="tx_en">With the evolution of computer vision, in recent times facial recognition systems have evolved from being based on 'interclass' and 'intraclass' variations to being directed towards strong artificial intelligence through machine learning. At the same time, privacy has become increasingly important due to the development of the internet and surveillance technology. In the future, technology will also gradually evolve towards 'passwordless' login, so the encryption and identification of physiological information will become a focus of research and development. For example, facial unlocking is currently one of the methods most commonly used for identity verification on personal mobile devices.</p>
<p class="tx_en">Through the face we visually perceive individuals directly (through the eyes) or indirectly, ie. through other means such as screens. The work <i>"It Could Be You"</i> uses the online pseudonym of the real-time message sender as a key to search for facial images, creating a large number of different Asian faces and fake personal information through synthetic data and machine learning that creates the illusion of a potential identity. This is an attempt to question and reveal the digital footprint in a vast network data base as a software system that could come close to human imagination or memory recollection. Instead of receiving and understanding the image through the refraction of light and the chemical and physiological changes in the brain, the process used is based on a calculation of each pixel dot that recognises facial features and individual characteristics through a series of operations. When the computer software recognises the human form as an object, it 'learns' how to physically define a person based on their type and appearance and, with the added logic of whether or not the object is moving, it can more accurately confirm that this is a subject rather than a static mannequin. The software enhances the definition of objects or events by referencing the parameters and changes of behaviour and environment.</p>
<p class="tx_en">The work <i>"Portrait 2011"</i> uses recycled materials to create a mechanical human head that attempts to express human emotions. When there is no one at the exhibition space, the device will start to cry and shed tears. Many people hide their crying when they are emotionally unstable. This is a quiet and secretive emotion difficult to express on a cold and mechanical object, but in the current analysis of consumer behaviour in online shopping, ie. tracking the preferences of advertisements, it may be possible to find similar expressions. Even when a certain type of product is more favorable, if consumers do not often browse this type of product, they will not receive newsletters or push notifications. This method of tracking consumer usage habits can be used to determine when to promote sales in order to boost them.</p>
<p class="tx_en">The construction of the aforementioned works is based on the data collection performed by basic network infrastructures. Another way to approach this can be found in CCTV closed-circuit and network photography systems, which in addition are subject to different regulations due to local laws. <i>"ID Photo Shooting Guide"</i> is a joint action in 2021 with Sandee CHAN and TAN Tsung Fan. The action originated when Sandee CHAN lost her ID card. Then, we used the IoT search engine "Shodan" to find low-security network cameras in Taipei city and determine their location to take ID photos. After the photos were processed, we went to the household affairs office to reissue the ID card. Simple hacking behaviour as the production of images, placing the image on a national identity card, is one of the starting points for this action. "ID Photo Shooting Guide On-Site" is a re-creation of the 2023 political university residence project that extends the 2021 version to be a physical device work.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Crystal Seeding</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/crystal-seeding/"/>
        <id>https://chenghsienyu.com/crystal-seeding/</id>
        <media:content url="https://chenghsienyu.com/media/posts/43/538e05b82b3e3d023d8e91efe0321c36.jpg" medium="image" />
            <category term="Project &amp; Work"/>
            <category term="2021"/>

        <updated>2023-01-01T22:57:40+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/43/538e05b82b3e3d023d8e91efe0321c36.jpg" alt="" />
                    等晶播種 3D printing installation, robotic arm installation, instrument installation, three-channel video installation, 32’15”3D列印裝置、機械手臂裝置、樂器裝置、三頻道錄像裝置，32分15秒,2021 “Crystal Seeding” is a joint artwork of&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/43/538e05b82b3e3d023d8e91efe0321c36.jpg" class="type:primaryImage" alt="" /></p>
                <div class="workTitle">等晶播種</div>
<div class="workPlaceYear">3D printing installation, robotic arm installation, instrument installation, three-channel video installation, 32’15”3D列印裝置、機械手臂裝置、樂器裝置、三頻道錄像裝置，32分15秒,2021</div>
<div> </div>
<div>
<p>“Crystal Seeding” is a joint artwork of three artists, Chia-wei Hsu, Hsien-yu Cheng, Ting-tong Chang in cooperation with Huwei Sugar Factory, Taiwan. The project took cane sugar as a starting point, and then developed by incorporating a puppet show, experimental music, sugar 3D printing technology and mechanical arms. Through this complicated yet interrelated network, this project aims to comb Huwei’s history during the last one hundred years.</p>
<p>The narrative for the video was adapted from the Japanized puppet show “Kurama Tengu” and was performed by the Sheng Ping Puppet Troupe. It combines both reality and the virtual to reveal the history of Huwei town. It is also interspersed with the performance of the composer, Tak-cheung Hui, at the Huwei sugar factory, transforming the factory into an on-site instrument. In this theater-like environment, the mechanical arm, 3D printer and aviation flag have all become actors in this play. They enter and exit the stage as the story unfolds, serving and portraying different “roles” and “incidents''.</p>
<p>《等晶播種》為許家維、鄭先喻、張碩尹三位藝術家共同製作。本計劃與台糖虎尾糖廠合作，以蔗糖為引子，延伸出布袋戲、實驗音樂、糖3D列印科技與機械手臂，並在此複雜又彼此關聯的網絡中爬梳過去百年的小鎮歷史。​</p>
<p>​</p>
<p>影片裡的敘事改寫自皇民化布袋戲《鞍馬天狗》(Kurama Tengu)，由戲團昇平五洲園(Sheng Ping Puppet Troupe)演出，現實結合虛擬，訴說虎尾鎮歷史；影片穿插作曲家許德彰在虎尾糖廠內的演奏，將工廠轉化成現地「樂器」；在如同劇場的環境中，機械手臂、3D列印機、航空旗號均為劇目中的演員，隨著故事推演而入場出場，在舞台中扮演不同的「角色」與「事件」。</p>
<div class="post__iframe"><iframe loading="lazy" width="640" height="360" src="https://player.vimeo.com/video/672710871?h=70f700f0a8&dnt=1" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen="allowfullscreen" data-mce-fragment="1"></iframe></div>
<p><a href="https://vimeo.com/672710871">Crystal Seeding</a> from <a href="https://vimeo.com/tingtongchang">Ting Tong Chang</a> on <a href="https://vimeo.com">Vimeo</a>.</p>
</div>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Happens To Be Performing</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/happens-to-be-performing/"/>
        <id>https://chenghsienyu.com/happens-to-be-performing/</id>
        <media:content url="https://chenghsienyu.com/media/posts/41/demo_a.png" medium="image" />
            <category term="Project &amp; Work"/>
            <category term="2022"/>

        <updated>2023-01-04T00:45:26+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/41/demo_a.png" alt="" />
                    鄭先喻 X 陳武康 CHENG Hsien-Yu X CHEN Wu-Kang 2022 軟體視覺化、機器學習、印表機、螢幕、現場演出 Visualized software, machine learning, printer, screen, on-site performance 本次作品『Happens to&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/41/demo_a.png" class="type:primaryImage" alt="" /></p>
                <div id="comp-l9lnw0kb" class="KcpHeO tz5f0K comp-l9lnw0kb" data-scope="" data-repeater-items-indexes="" data-testid="richTextElement">
<h3 class="font_3">鄭先喻 X 陳武康 CHENG Hsien-Yu X CHEN Wu-Kang</h3>
</div>
<div id="comp-l9lnw0kd1" class="KcpHeO tz5f0K comp-l9lnw0kd1" data-scope="" data-repeater-items-indexes="" data-testid="richTextElement">
<p class="font_8"><span class="color_15">2022</span></p>
<p class="font_8"><span class="color_15">軟體視覺化、機器學習、印表機、螢幕、現場演出</span></p>
<div id="comp-l9lnw0kd1" class="KcpHeO tz5f0K comp-l9lnw0kd1" data-testid="richTextElement">
<p class="font_8"><span class="color_15">Visualized software, machine learning, printer, screen, on-site performance</span></p>
</div>
<div id="comp-l9lnw0kh" class="comp-l9lnw0kh o_23ep" role="region" data-testid="slide-show-gallery" data-image-mode="clipImage" aria-label="Slide show gallery">
<div class="ZTB3Xl">
<div class="Wh6lWl zT_qMU" data-testid="gallery-item-ghost" data-image-mode="clipImage">
<div class="QS8h3m gnxWt2" tabindex="0" role="button" data-testid="gallery-item-click-action-image-zoom" aria-haspopup="true" aria-label="BN-04-20221027-ns-2-034" aria-describedby="describedby_item-0-comp-l9lnw0kh">
<div class="NBLBbN">
<div class="x2q2kn">
<div class="u2zCj9"><img loading="lazy" src="https://static.wixstatic.com/media/cd54bf_298bb9c1a39a429fa23833c7c4436cbb~mv2.jpg/v1/fill/w_1822,h_1024,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/cd54bf_298bb9c1a39a429fa23833c7c4436cbb~mv2.jpg" alt="BN-04-20221027-ns-2-034" data-is-external-image="true"></div>
</div>
</div>
<div class="UcEVc5 JbGmiU" data-testid="gallery-item-panel">
<div class="gy3LbX" data-testid="gallery-item-title"> </div>
<p class="WY_zBV" data-testid="gallery-item-description"> </p>
</div>
<div class="Wh6lWl zT_qMU" data-testid="gallery-item-ghost" data-image-mode="clipImage">
<div class="QS8h3m gnxWt2" tabindex="0" role="button" data-testid="gallery-item-click-action-image-zoom" aria-haspopup="true" aria-label="&quot;Happens to Be Performing&quot; Opening Show Photoshoot" aria-describedby="describedby_item-1-comp-l9lnw0kh">
<div class="NBLBbN">
<div class="x2q2kn">
<div class="u2zCj9"><img loading="lazy" src="https://static.wixstatic.com/media/cd54bf_47115cce9e9846d1b72c996918d54ff9~mv2.jpg/v1/fill/w_1822,h_1024,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/cd54bf_47115cce9e9846d1b72c996918d54ff9~mv2.jpg" alt="&quot;Happens to Be Performing&quot; Opening Show Photoshoot" data-is-external-image="true"></div>
</div>
</div>
<div class="UcEVc5 JbGmiU" data-testid="gallery-item-panel">
<div class="gy3LbX" data-testid="gallery-item-title"> </div>
<p class="WY_zBV" data-testid="gallery-item-description"> </p>
</div>
<div class="Wh6lWl zT_qMU" data-testid="gallery-item-ghost" data-image-mode="clipImage">
<div class="QS8h3m gnxWt2" tabindex="0" role="button" data-testid="gallery-item-click-action-image-zoom" aria-haspopup="true" aria-describedby="describedby_item-6-comp-l9lnw0kh">
<div class="NBLBbN">
<div class="x2q2kn">
<div class="u2zCj9"><img loading="lazy" src="https://static.wixstatic.com/media/cd54bf_96748828e2d54bbda13a31ee29dc92b3~mv2.jpg/v1/fill/w_1822,h_1024,al_c,q_85,usm_0.66_1.00_0.01,enc_auto/cd54bf_96748828e2d54bbda13a31ee29dc92b3~mv2.jpg" alt="" data-is-external-image="true"></div>
</div>
</div>
<div class="UcEVc5 JbGmiU" data-testid="gallery-item-panel">
<div class="gy3LbX" data-testid="gallery-item-title"> </div>
<p class="WY_zBV" data-testid="gallery-item-description"> </p>
</div>
<nav class="gAvFno" aria-label="slides" data-testid="gallery-navButtons"></nav></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<p class="s7"><span class="s11">本次作品『</span><span class="s12">Happens to be performing</span><span class="s11">』將由</span><span class="s12">2019</span><span class="s11">至今的軟體所蒐集到的網路留言資料庫中，建置文本語義模型，規劃每一週產出一次劇本生成，並視覺化文本再以現場的事務印表機裝置去藉由表演者，以隨機觸發劇本生成的方式，在現場取得列印出的文本，做出臨時並且即興的演出嘗試。</span></p>
<p class="s7"> </p>
<p class="s7"><span class="s11">＊作品源自</span><span class="s12">2019</span><span class="s11">年個展同化者中的無名作品，該作品前身也與張碩尹與廖銘和的臺北機電人</span><span class="s12">2.0</span><span class="s11">一展中，作為控制現場裝置與聲音以及顯示網路民眾即時留言與對話訊息展出，在發展時，原計劃為將網路民眾的留言與即時聊天訊息資料藉由機器學習，去制定出語意的模型與說話的方式，再由機器學習產出劇本。</span></p>
<p class="font_8">Happens to Be Performing originated from an untitled work in Cheng Hsien-Yu’s 2019 solo exhibition “Assimilator.” The earlier version of the work was also presented during Chang Ting-Tong and Liao Ming-Ho’s 2020 exhibition “Taipei Robot Man 2.0.” The work uses internet installations to extract messages and conversations of people on the internet, which are retracted and transcoded into a driving force for the on-site installation and sound.</p>
<p class="font_8"> </p>
<p class="font_8">This presentation takes a step further and incorporates machine learning to construct a semantic text model through a database of online messages that are collected from 2019 to the present moment, to produce instant play scripts. This work was created in collaboration with choreographer/interdisciplinary artist Chen Wu-Kang, who activates the printers on site and plays chess with printed AI visual texts, leading to random and impromptu performances.</p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="5">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_3b60094f569b462da1463ed9f4b4175c~mv2.jpg" data-size="2000x1333"><img loading="lazy" src="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_3b60094f569b462da1463ed9f4b4175c~mv2-thumbnail.webp" alt="" width="720" height="480"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_429d40e5f7944b62816a7c25f95c5b89~mv2.jpg" data-size="2000x1125"><img loading="lazy" src="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_429d40e5f7944b62816a7c25f95c5b89~mv2-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_780dcec23d0a409e931ac8f14be42d17~mv2.jpg" data-size="2000x1125"><img loading="lazy" src="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_780dcec23d0a409e931ac8f14be42d17~mv2-thumbnail.webp" alt="" width="720" height="405"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_ac1899dda46441f581e8aab15d0c752a~mv2.jpg" data-size="2000x1334"><img loading="lazy" src="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_ac1899dda46441f581e8aab15d0c752a~mv2-thumbnail.webp" alt="" width="720" height="480"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_96748828e2d54bbda13a31ee29dc92b3~mv2.jpg" data-size="2000x1125"><img loading="lazy" src="https://chenghsienyu.com/media/posts/41/gallery/cd54bf_96748828e2d54bbda13a31ee29dc92b3~mv2-thumbnail.webp" alt="" width="720" height="405"></a></figure>
</div></div>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/h9QR12XrYYA?start=49" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></div>
<p> </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Minimal Input @ C-lab</title>
        <author>
            <name>HsienYu Cheng｜鄭先喻</name>
        </author>
        <link href="https://chenghsienyu.com/minimal-input-c-lab/"/>
        <id>https://chenghsienyu.com/minimal-input-c-lab/</id>
        <media:content url="https://chenghsienyu.com/media/posts/40/DSC3331-Large.jpeg" medium="image" />
            <category term="Project &amp; Work"/>
            <category term="2022"/>

        <updated>2023-01-03T21:59:49+08:00</updated>
            <summary>
                <![CDATA[
                        <img src="https://chenghsienyu.com/media/posts/40/DSC3331-Large.jpeg" alt="" />
                    Event link : https://clab.org.tw/en/events/minimal_input_2022 Live Performance feat. installation work 「我們正在談論你是如何統治」 "We are just saying how you are ruling" 鄭先喻 |&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                    <p><img src="https://chenghsienyu.com/media/posts/40/DSC3331-Large.jpeg" class="type:primaryImage" alt="" /></p>
                <p>Event link : <a href="https://clab.org.tw/en/events/minimal_input_2022" target="_blank" rel="noopener noreferrer">https://clab.org.tw/en/events/minimal_input_2022</a></p>
<p>Live Performance feat. installation work</p>
<hr>
<p><span lang="ZH-TW" xml:lang="ZH-TW" data-contrast="none">「我們正在談論你是如何統治」<br></span><span lang="ZH-TW" xml:lang="ZH-TW" data-contrast="none"><strong><em><a href="https://chenghsienyu.com/we-are-just-saying-what-you-are-ruling/">"We are just saying how you are ruling"</a></em></strong><br>鄭先喻 <span data-ccp-charstyle="spellingerror" data-ccp-charstyle-defn="{">| </span></span><span data-contrast="none">人工智慧生成音像</span><span data-contrast="none"> | 8'12" | </span><span data-contrast="none">2020</span><span data-ccp-props="{"> </span></p>
<p><span data-contrast="none">運用網路搜尋圖像與「機器學習」方式創作，大量即時抓取「人類破壞生態」關鍵字圖像，以第一人稱、也就是電腦以「我」譴責人類因開發、浪費、 貪婪而導致生態滅絕的圖像投影與字句，可怕的是，電腦經由「自主學習」並「增強更新」演算法與數據分析做出準確預測而逐漸成為「全知者」，多數人類乃至國家逐 漸無法操控數據反而被數據操控，並藉由特意使機器學習模型辨識錯誤，軟體會將污染與環境破壞圖像形容為美好的日常事物。</span></p>
<div class="gallery-wrapper"><div class="gallery"  data-is-empty="false" data-translation="Add images" data-columns="3">
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/40/gallery/DSC3331-Large.jpeg" data-size="1280x854"><img loading="lazy" src="https://chenghsienyu.com/media/posts/40/gallery/DSC3331-Large-thumbnail.webp" alt="" width="720" height="480"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/40/gallery/DSC3333-Large.jpeg" data-size="1280x854"><img loading="lazy" src="https://chenghsienyu.com/media/posts/40/gallery/DSC3333-Large-thumbnail.webp" alt="" width="720" height="480"></a></figure>
<figure class="gallery__item"><a href="https://chenghsienyu.com/media/posts/40/gallery/DSC3334-Large.jpeg" data-size="1280x854"><img loading="lazy" src="https://chenghsienyu.com/media/posts/40/gallery/DSC3334-Large-thumbnail.webp" alt="" width="720" height="480"></a></figure>
</div></div>
<div class="post__iframe"><iframe loading="lazy" width="560" height="315" src="https://www.youtube-nocookie.com/embed/FrPuAo8lXzM?start=220" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></div>
            ]]>
        </content>
    </entry>
</feed>
